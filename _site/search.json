[
  {
    "objectID": "content/03_other/06_links.html",
    "href": "content/03_other/06_links.html",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual .\n\n\n\n\nGoogle is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "content/03_other/06_links.html#r-and-r-studio",
    "href": "content/03_other/06_links.html#r-and-r-studio",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual ."
  },
  {
    "objectID": "content/03_other/06_links.html#additional-r-resources",
    "href": "content/03_other/06_links.html#additional-r-resources",
    "title": "Links",
    "section": "",
    "text": "Google is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "content/01_journal/04_performance_measures.html",
    "href": "content/01_journal/04_performance_measures.html",
    "title": "Performance Measures",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\nlibrary(h2o)\nlibrary(dplyr)\nlibrary(purrr)\nlibrary(rsample)\nlibrary(recipes)\nI had difficulties calculating models within the enviroment of Quarto. That’s why I executed the code in another independent R script and just exported the plots and the tables. The code however is shown here for the purpose of evaluation.\nIf something is not clear, please look at the comments I made in the code. I tried to document my process there."
  },
  {
    "objectID": "content/01_journal/04_performance_measures.html#leaderboard-visualization",
    "href": "content/01_journal/04_performance_measures.html#leaderboard-visualization",
    "title": "Performance Measures",
    "section": "\n1.1 Leaderboard Visualization",
    "text": "1.1 Leaderboard Visualization\n\n####LEADERBOARD VISUALIZATION###\nleaderboard_sorted &lt;- automl_models_h2o@leaderboard %&gt;% \n  as_tibble() %&gt;% \n  select(-c(mean_per_class_error, rmse, mse))\n\nHere is the leaderboard from the preceded calculation.\n\nread_csv(\"04_performance_measures_files/leaderboard_sorted.csv\")\n\n#&gt; Rows: 14 Columns: 4\n#&gt; ── Column specification ────────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; chr (1): model_id\n#&gt; dbl (3): auc, logloss, aucpr\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n  \n\n\n\n\n# Visualize the H2O leaderboard to help with model selection\ndata_transformed_tbl &lt;- automl_models_h2o@leaderboard %&gt;%\n  as_tibble() %&gt;%\n  select(-c(aucpr, mean_per_class_error, rmse, mse)) %&gt;% \n  mutate(model_type = str_extract(model_id, \"[^_]+\")) %&gt;%\n  slice(1:15) %&gt;% \n  rownames_to_column(var = \"rowname\") %&gt;%\n  # Visually this step will not change anything\n  # It reorders the factors under the hood\n  mutate(\n    model_id   = as_factor(model_id) %&gt;% reorder(auc),\n    model_type = as.factor(model_type)\n  ) %&gt;% \n  pivot_longer(cols = -c(model_id, model_type, rowname), \n               names_to = \"key\", \n               values_to = \"value\", \n               names_transform = list(key = forcats::fct_inorder)\n  ) %&gt;% \n  mutate(model_id = paste0(rowname, \". \", model_id) %&gt;% as_factor() %&gt;% fct_rev())\n\nThe table looks like this.\n\nread_csv(\"04_performance_measures_files/calculated_gain_lift_tbl.csv\")\n\n#&gt; Rows: 10 Columns: 10\n#&gt; ── Column specification ────────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; dbl (10): group, cases, responses, cumulative_responses, pct_responses, gain...\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n  \n\n\n\n\n#Plot the data\ndata_transformed_tbl %&gt;%\n  ggplot(aes(value, model_id, color = model_type)) +\n  geom_point(size = 3) +\n  geom_label(aes(label = round(value, 2), hjust = \"inward\")) +\n  \n  # Facet to break out logloss and auc\n  facet_wrap(~ key, scales = \"free_x\") +\n  labs(title = \"Leaderboard Metrics\",\n       subtitle = paste0(\"Ordered by: \", \"auc\"),\n       y = \"Model Postion, Model ID\", x = \"\") + \n  theme(legend.position = \"bottom\")\n\nAnd the plot looks as follows:\n I just copied the following code from the business case.\n\n#Function for what we did above (plotting)\nplot_h2o_leaderboard &lt;- function(h2o_leaderboard, order_by = c(\"auc\", \"logloss\"), \n                                 n_max = 20, size = 4, include_lbl = TRUE) {\n  \n  # Setup inputs\n  # adjust input so that all formats are working\n  order_by &lt;- tolower(order_by[[1]])\n  \n  leaderboard_tbl &lt;- h2o_leaderboard %&gt;%\n    as.tibble() %&gt;%\n    select(-c(aucpr, mean_per_class_error, rmse, mse)) %&gt;% \n    mutate(model_type = str_extract(model_id, \"[^_]+\")) %&gt;%\n    rownames_to_column(var = \"rowname\") %&gt;%\n    mutate(model_id = paste0(rowname, \". \", model_id) %&gt;% as.factor())\n  \n  # Transformation\n  if (order_by == \"auc\") {\n    \n    data_transformed_tbl &lt;- leaderboard_tbl %&gt;%\n      slice(1:n_max) %&gt;%\n      mutate(\n        model_id   = as_factor(model_id) %&gt;% reorder(auc),\n        model_type = as.factor(model_type)\n      ) %&gt;%\n      pivot_longer(cols = -c(model_id, model_type, rowname), \n                   names_to = \"key\", \n                   values_to = \"value\", \n                   names_transform = list(key = forcats::fct_inorder)\n      )\n    \n  } else if (order_by == \"logloss\") {\n    \n    data_transformed_tbl &lt;- leaderboard_tbl %&gt;%\n      slice(1:n_max) %&gt;%\n      mutate(\n        model_id   = as_factor(model_id) %&gt;% reorder(logloss) %&gt;% fct_rev(),\n        model_type = as.factor(model_type)\n      ) %&gt;%\n      pivot_longer(cols = -c(model_id, model_type, rowname), \n                   names_to = \"key\", \n                   values_to = \"value\", \n                   names_transform = list(key = forcats::fct_inorder)\n      )\n    \n  } else {\n    # If nothing is supplied\n    stop(paste0(\"order_by = '\", order_by, \"' is not a permitted option.\"))\n  }\n  \n  # Visualization\n  g &lt;- data_transformed_tbl %&gt;%\n    ggplot(aes(value, model_id, color = model_type)) +\n    geom_point(size = size) +\n    facet_wrap(~ key, scales = \"free_x\") +\n    labs(title = \"Leaderboard Metrics\",\n         subtitle = paste0(\"Ordered by: \", toupper(order_by)),\n         y = \"Model Postion, Model ID\", x = \"\")\n  \n  if (include_lbl) g &lt;- g + geom_label(aes(label = round(value, 2), \n                                           hjust = \"inward\"))\n  \n  return(g)\n  \n}\n\nI saved the following models from my calculation to compare later on.\n\n#Save some models to compare\n#StackedEnsemble\nh2o.getModel(\"StackedEnsemble_BestOfFamily_2_AutoML_7_20230613_130012\") %&gt;% \n  h2o.saveModel(path = \"h2o_models_new\")\n#GBM\nh2o.getModel(\"GBM_4_AutoML_7_20230613_130012\") %&gt;% \n  h2o.saveModel(path = \"h2o_models_new\")\n#GLM\nh2o.getModel(\"GLM_1_AutoML_7_20230613_130012\") %&gt;%\n  h2o.saveModel(path = \"h2o_models_new\")\n\n#load gbm model and predict\ngbm_h2o &lt;- h2o.loadModel(\"/Users/Amin/Documents/GitHub/ss23-bdml-aminraza/content/01_journal/h2o_models_new/GBM_4_AutoML_7_20230613_130012\")\n\npredictions &lt;- h2o.predict(gbm_h2o, newdata = as.h2o(test_tbl))\n\npredictions_tbl &lt;- predictions %&gt;% as_tibble()\n\nNext we will perform the Grid Search."
  },
  {
    "objectID": "content/01_journal/04_performance_measures.html#grid-search",
    "href": "content/01_journal/04_performance_measures.html#grid-search",
    "title": "Performance Measures",
    "section": "\n1.2 Grid Search",
    "text": "1.2 Grid Search\n\n#####GRID SEARCH#####\n\n#We already did that prior to the prediction, allthough prediction is not relevant yet in this challenge\n#stacked_ensemble_h2o &lt;- h2o.loadModel(\"h20_models/StackedEnsemble_BestOfFamily_2_AutoML_7_20230610_121949\")\n\n# Take a look for the metrics on the training data set\n# For my model the total error in the confusion matrix is ~4,5 %\ngbm_h2o\n\n# We want to see how it performs for the testing data frame\ntest_tbl\n\n# Make sure to convert it to an h20 object\n# Accuracy of the confusion matrix shows ~95 % accuracy\nh2o.performance(gbm_h2o, newdata = as.h2o(test_tbl))\n\n?h2o.grid()\n\ngbm_grid_01 &lt;- h2o.grid(\n  \n  # See help page for available algos\n  algorithm = \"gbm\",\n  \n  # I just use the same as the object\n  grid_id = \"gbm_grid_01\",\n  \n  # The following is for ?h2o.deeplearning()\n  # predictor and response variables\n  x = x,\n  y = y,\n  \n  # training and validation frame and crossfold validation\n  training_frame   = train_h2o,\n  validation_frame = valid_h2o,\n  nfolds = 5,\n  \n  # Hyperparamters: I use the ones which I can use for GBM\n  hyper_params = list(\n    # Use some combinations (the first one was the original)\n    ntrees = list(c(10)),\n    max_depth = c(12,10,8))\n)\n\ngbm_grid_01\n\nh2o.getGrid(grid_id = \"gbm_grid_01\", sort_by = \"auc\", decreasing = TRUE)\n\n#See how the model performs on test data\n\ngbm_grid_01_model_2 &lt;- h2o.getModel(\"gbm_grid_01_model_2\")\n\ngbm_grid_01_model_2 %&gt;% h2o.auc(train = T, valid = T, xval = T)\n\n# Run it on the test data\ngbm_grid_01_model_2 %&gt;%\n  h2o.performance(newdata = as.h2o(test_tbl))\n# error is ~8.7 % (Confusion matrix)\n\n\n#Performance of old model\ngbm_h2o %&gt;%\n  h2o.performance(newdata = as.h2o(test_tbl))\n# error is 8,9 %\n\nAs you could see in my comments in the code, the error of the optimized model is ca. 8,7 % (confusion matrix). The error of the old unoptimzed model is ca. 8,9 %. So the difference is only 0,2 %."
  },
  {
    "objectID": "content/01_journal/04_performance_measures.html#h2o-performance",
    "href": "content/01_journal/04_performance_measures.html#h2o-performance",
    "title": "Performance Measures",
    "section": "\n1.3 H2O Performance",
    "text": "1.3 H2O Performance\nVisualize the trade of between the precision and the recall and the optimal threshold\n\n#load a few models\n\nstacked_ensemble_h2o &lt;- h2o.loadModel(\"/Users/Amin/Documents/GitHub/ss23-bdml-aminraza/content/01_journal/h2o_models_new/StackedEnsemble_BestOfFamily_2_AutoML_7_20230613_130012\")\n\ngbm_h2o &lt;- h2o.loadModel(\"/Users/Amin/Documents/GitHub/ss23-bdml-aminraza/content/01_journal/h2o_models_new/GBM_4_AutoML_7_20230613_130012\")\n\nglm_h2o &lt;- h2o.loadModel(\"/Users/Amin/Documents/GitHub/ss23-bdml-aminraza/content/01_journal/h2o_models_new/GLM_1_AutoML_7_20230613_130012\")\n\n#Create a performance object\nperformance_h2o &lt;- h2o.performance(stacked_ensemble_h2o, newdata = as.h2o(test_tbl))\n\ntypeof(performance_h2o)\n#S4\nperformance_h2o %&gt;% slotNames()\n\n# We are focusing on the slot metrics. This slot contains all possible metrics\nperformance_h2o@metrics\n\n# Classifier Summary Metrics\n\nh2o.auc(performance_h2o, train = T, valid = T, xval = T)\n\ntrain       valid       xval\n0.9517821   0.9042058   0.9170230\n\n# Caution: \"train, \"val\", and \"xval\" arugments only work for models (not performance objects)\nh2o.auc(stacked_ensemble_h2o, train = T, valid = T, xval = T)\n\n[1] 0.9514619\n\nh2o.giniCoef(performance_h2o)\n\nh2o.logloss(performance_h2o)\n\n\n# result for the training data\nh2o.confusionMatrix(stacked_ensemble_h2o)\n\n\n# result for the hold out set\nh2o.confusionMatrix(performance_h2o)\n\n# Precision vs Recall Plot\n\n# This is on the test set\nperformance_tbl &lt;- performance_h2o %&gt;%\n  h2o.metric() %&gt;%\n  as_tibble() \n\nperformance_tbl %&gt;% \n  glimpse()\n\ntheme_new &lt;- theme(\n  legend.position  = \"bottom\",\n  legend.key       = element_blank(),,\n  panel.background = element_rect(fill   = \"transparent\"),\n  panel.border     = element_rect(color = \"black\", fill = NA, size = 0.5),\n  panel.grid.major = element_line(color = \"grey\", size = 0.333)\n) \n\nperformance_tbl %&gt;%\n  filter(f1 == max(f1))\n\nperformance_tbl %&gt;%\n  ggplot(aes(x = threshold)) +\n  geom_line(aes(y = precision), color = \"blue\", size = 1) +\n  geom_line(aes(y = recall), color = \"red\", size = 1) +\n  \n  # Insert line where precision and recall are harmonically optimized\n  geom_vline(xintercept = h2o.find_threshold_by_max_metric(performance_h2o, \"f1\")) +\n  labs(title = \"Precision vs Recall\", y = \"value\") +\n  theme_new\n\n\n\nPrecesion vs Recall Plot"
  },
  {
    "objectID": "content/01_journal/04_performance_measures.html#roc-plot",
    "href": "content/01_journal/04_performance_measures.html#roc-plot",
    "title": "Performance Measures",
    "section": "\n1.4 ROC Plot",
    "text": "1.4 ROC Plot\n\n# ROC Plot\n\npath &lt;- \"h2o_models_new/GLM_1_AutoML_9_20230611_174526\"\n\nload_model_performance_metrics &lt;- function(path, test_tbl) {\n  \n  model_h2o &lt;- h2o.loadModel(path)\n  perf_h2o  &lt;- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) \n  \n  perf_h2o %&gt;%\n    h2o.metric() %&gt;%\n    as_tibble() %&gt;%\n    mutate(auc = h2o.auc(perf_h2o)) %&gt;%\n    select(tpr, fpr, auc)\n  \n}\n\nmodel_metrics_tbl &lt;- fs::dir_info(path = \"h2o_models_new\") %&gt;%\n  select(path) %&gt;%\n  mutate(metrics = map(path, load_model_performance_metrics, test_tbl)) %&gt;%\n  unnest(cols = metrics)\n\n\nmodel_metrics_tbl %&gt;%\n  mutate(\n    # Extract the model names\n    path = str_split(path, pattern = \"/\", simplify = T)[,2] %&gt;% as_factor(),\n    auc  = auc %&gt;% round(3) %&gt;% as.character() %&gt;% as_factor()\n  ) %&gt;%\n  ggplot(aes(fpr, tpr, color = path, linetype = auc)) +\n  geom_line(size = 1) +\n  \n  # just for demonstration purposes\n  geom_abline(color = \"red\", linetype = \"dotted\") +\n  \n  theme_new +\n  theme(\n    legend.direction = \"vertical\",\n  ) +\n  labs(\n    title = \"ROC Plot\",\n    subtitle = \"Performance of 3 Top Performing Models\"\n  )\n\n\n\nROC Plot\n\nYou can clearly see, that the GLM Model performs the worst. This no surprise since it was the very last model on the leaderboard. The difference on the other two models however is close to zero."
  },
  {
    "objectID": "content/01_journal/04_performance_measures.html#precision-vs-recall-plot",
    "href": "content/01_journal/04_performance_measures.html#precision-vs-recall-plot",
    "title": "Performance Measures",
    "section": "\n1.5 Precision vs Recall Plot",
    "text": "1.5 Precision vs Recall Plot\n\n# Precision vs Recall\n\nload_model_performance_metrics2 &lt;- function(path, test_tbl) {\n  \n  model_h2o &lt;- h2o.loadModel(path)\n  perf_h2o  &lt;- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) \n  \n  perf_h2o %&gt;%\n    h2o.metric() %&gt;%\n    as_tibble() %&gt;%\n    mutate(auc = h2o.auc(perf_h2o)) %&gt;%\n    select(tpr, fpr, auc, precision, recall)\n  \n}\n\nmodel_metrics_tbl_2 &lt;- fs::dir_info(path = \"h2o_models_new\") %&gt;%\n  select(path) %&gt;%\n  mutate(metrics = map(path, load_model_performance_metrics2, test_tbl)) %&gt;%\n  unnest(cols = metrics)\n\nmodel_metrics_tbl_2 %&gt;%\n  mutate(\n    path = str_split(path, pattern = \"/\", simplify = T)[,2] %&gt;% as_factor(),\n    auc  = auc %&gt;% round(3) %&gt;% as.character() %&gt;% as_factor()\n  ) %&gt;%\n  ggplot(aes(recall, precision, color = path, linetype = auc)) +\n  geom_line(size = 1) +\n  theme_new + \n  theme(\n    legend.direction = \"vertical\",\n  ) +\n  labs(\n    title = \"Precision vs Recall Plot\",\n    subtitle = \"Performance of 3 Top Performing Models\"\n  )\n\n\n\nROC Plot\n\nSame here. GLM in comparison performs the worst."
  },
  {
    "objectID": "content/01_journal/04_performance_measures.html#gain-lift",
    "href": "content/01_journal/04_performance_measures.html#gain-lift",
    "title": "Performance Measures",
    "section": "\n1.6 Gain & Lift",
    "text": "1.6 Gain & Lift\n\n# Gain & Lift\n\n#Because we need our predictions again we calculate a prediction of the best performing model we have in this session\n#Best Performing Model: stacked ensenmble\n\npredictions &lt;- h2o.predict(stacked_ensemble_h2o, newdata = as.h2o(test_tbl))\n\npredictions_tbl &lt;- predictions %&gt;% as_tibble()\n\nranked_predictions_tbl &lt;- predictions_tbl %&gt;%\n  bind_cols(test_tbl) %&gt;%\n  select(predict:Yes, went_on_backorder) %&gt;%\n  # Sorting from highest to lowest class probability\n  arrange(desc(Yes))\n\n\nread_csv(\"04_performance_measures_files/ranked_predictions_tbl.csv\")\n\n#&gt; Rows: 2858 Columns: 4\n#&gt; ── Column specification ────────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; chr (2): predict, went_on_backorder\n#&gt; dbl (2): No, Yes\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n  \n\n\n\n\nranked_predictions_tbl %&gt;%\n  mutate(ntile = ntile(Yes, n = 10)) %&gt;%\n  group_by(ntile) %&gt;%\n  summarise(\n    cases = n(),\n    responses = sum(went_on_backorder == \"Yes\")\n  ) %&gt;%\n  arrange(desc(ntile))\n\n\nread_csv(\"04_performance_measures_files/ranked_predictions_step2.csv\")\n\n#&gt; Rows: 2858 Columns: 4\n#&gt; ── Column specification ────────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; chr (2): predict, went_on_backorder\n#&gt; dbl (2): No, Yes\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n  \n\n\n\nLook at the 10 ntile: 213 of 285 went actually on backorder.\n\ncalculated_gain_lift_tbl &lt;- ranked_predictions_tbl %&gt;%\n  mutate(ntile = ntile(Yes, n = 10)) %&gt;%\n  group_by(ntile) %&gt;%\n  summarise(\n    cases = n(),\n    responses = sum(went_on_backorder == \"Yes\")\n  ) %&gt;%\n  arrange(desc(ntile)) %&gt;%\n  \n  # Add group numbers (opposite of ntile)\n  mutate(group = row_number()) %&gt;%\n  select(group, cases, responses) %&gt;%\n  \n  # Calculations\n  mutate(\n    cumulative_responses = cumsum(responses),\n    pct_responses        = responses / sum(responses),\n    gain                 = cumsum(pct_responses),\n    cumulative_pct_cases = cumsum(cases) / sum(cases),\n    lift                 = gain / cumulative_pct_cases,\n    gain_baseline        = cumulative_pct_cases,\n    lift_baseline        = gain_baseline / cumulative_pct_cases\n  )\n\ncalculated_gain_lift_tbl \n\n\nread_csv(\"04_performance_measures_files/calculated_gain_lift_tbl.csv\")\n\n#&gt; Rows: 10 Columns: 10\n#&gt; ── Column specification ────────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; dbl (10): group, cases, responses, cumulative_responses, pct_responses, gain...\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n  \n\n\n\n\n#Calculating Gain & Lift manually was rather for understanding the concept.\n#Of course H2O can do the calculation for us.\n\ngain_lift_tbl &lt;- performance_h2o %&gt;%\n  h2o.gainsLift() %&gt;%\n  as.tibble()\n\n## Gain Chart\n\ngain_transformed_tbl &lt;- gain_lift_tbl %&gt;% \n  select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %&gt;%\n  select(-contains(\"lift\")) %&gt;%\n  mutate(baseline = cumulative_data_fraction) %&gt;%\n  rename(gain     = cumulative_capture_rate) %&gt;%\n  # prepare the data for the plotting (for the color and group aesthetics)\n  pivot_longer(cols = c(gain, baseline), values_to = \"value\", names_to = \"key\")\n\ngain_transformed_tbl %&gt;%\n  ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +\n  geom_line(size = 1.5) +\n  labs(\n    title = \"Gain Chart\",\n    x = \"Cumulative Data Fraction\",\n    y = \"Gain\"\n  ) +\n  theme_new\n\nGain Plot\n\n\nGain Plot\n\n\n## Lift Plot\n\nlift_transformed_tbl &lt;- gain_lift_tbl %&gt;% \n  select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %&gt;%\n  select(-contains(\"capture\")) %&gt;%\n  mutate(baseline = 1) %&gt;%\n  rename(lift = cumulative_lift) %&gt;%\n  pivot_longer(cols = c(lift, baseline), values_to = \"value\", names_to = \"key\")\n\nlift_transformed_tbl %&gt;%\n  ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +\n  geom_line(size = 1.5) +\n  labs(\n    title = \"Lift Chart\",\n    x = \"Cumulative Data Fraction\",\n    y = \"Lift\"\n  ) +\n  theme_new\n\nLift Plot\n\n\nGain Plot"
  },
  {
    "objectID": "content/01_journal/04_performance_measures.html#dashboard-with-cowplot",
    "href": "content/01_journal/04_performance_measures.html#dashboard-with-cowplot",
    "title": "Performance Measures",
    "section": "\n1.7 Dashboard with cowplot",
    "text": "1.7 Dashboard with cowplot\nHere comes a bunch of code I copied from the task description/tutorial. Of course I customized it with respect to my needs.\n\n# 5. Performance Visualization ----  \nlibrary(cowplot)\nlibrary(glue)\n\n\n# set values to test the function while building it\nh2o_leaderboard &lt;- automl_models_h2o@leaderboard\nnewdata &lt;- test_tbl\norder_by &lt;- \"auc\"\nmax_models &lt;- 4\nsize &lt;- 1\n\nplot_h2o_performance &lt;- function(h2o_leaderboard, newdata, order_by = c(\"auc\", \"logloss\"),\n                                 max_models = 3, size = 1.5) {\n  \n  # Inputs\n  \n  leaderboard_tbl &lt;- h2o_leaderboard %&gt;%\n    as_tibble() %&gt;%\n    slice(1:max_models)\n  \n  newdata_tbl &lt;- newdata %&gt;%\n    as_tibble()\n  \n  # Selecting the first, if nothing is provided\n  order_by      &lt;- tolower(order_by[[1]]) \n  \n  # Convert string stored in a variable to column name (symbol)\n  order_by_expr &lt;- rlang::sym(order_by)\n  \n  # Turn of the progress bars ( opposite h2o.show_progress())\n  h2o.no_progress()\n  \n  # 1. Model metrics\n  \n  get_model_performance_metrics &lt;- function(model_id, test_tbl) {\n    \n    model_h2o &lt;- h2o.getModel(model_id)\n    perf_h2o  &lt;- h2o.performance(model_h2o, newdata = as.h2o(test_tbl))\n    \n    perf_h2o %&gt;%\n      h2o.metric() %&gt;%\n      as.tibble() %&gt;%\n      select(threshold, tpr, fpr, precision, recall)\n    \n  }\n  \n  model_metrics_tbl &lt;- leaderboard_tbl %&gt;%\n    mutate(metrics = map(model_id, get_model_performance_metrics, newdata_tbl)) %&gt;%\n    unnest(cols = metrics) %&gt;%\n    mutate(\n      model_id = as_factor(model_id) %&gt;% \n        # programmatically reorder factors depending on order_by\n        fct_reorder(!! order_by_expr, \n                    .desc = ifelse(order_by == \"auc\", TRUE, FALSE)),\n      auc      = auc %&gt;% \n        round(3) %&gt;% \n        as.character() %&gt;% \n        as_factor() %&gt;% \n        fct_reorder(as.numeric(model_id)),\n      logloss  = logloss %&gt;% \n        round(4) %&gt;% \n        as.character() %&gt;% \n        as_factor() %&gt;% \n        fct_reorder(as.numeric(model_id))\n    )\n  \n  \n  # 1A. ROC Plot\n  \n  p1 &lt;- model_metrics_tbl %&gt;%\n    ggplot(aes(fpr, tpr, color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size) +\n    theme_new +\n    labs(title = \"ROC\", x = \"FPR\", y = \"TPR\") +\n    theme(legend.direction = \"vertical\") \n  \n  \n  # 1B. Precision vs Recall\n  \n  p2 &lt;- model_metrics_tbl %&gt;%\n    ggplot(aes(recall, precision, color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size) +\n    theme_new +\n    labs(title = \"Precision Vs Recall\", x = \"Recall\", y = \"Precision\") +\n    theme(legend.position = \"none\") \n  \n  \n  # 2. Gain / Lift\n  \n  get_gain_lift &lt;- function(model_id, test_tbl) {\n    \n    model_h2o &lt;- h2o.getModel(model_id)\n    perf_h2o  &lt;- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) \n    \n    perf_h2o %&gt;%\n      h2o.gainsLift() %&gt;%\n      as.tibble() %&gt;%\n      select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift)\n    \n  }\n  \n  gain_lift_tbl &lt;- leaderboard_tbl %&gt;%\n    mutate(metrics = map(model_id, get_gain_lift, newdata_tbl)) %&gt;%\n    unnest(cols = metrics) %&gt;%\n    mutate(\n      model_id = as_factor(model_id) %&gt;% \n        fct_reorder(!! order_by_expr, \n                    .desc = ifelse(order_by == \"auc\", TRUE, FALSE)),\n      auc  = auc %&gt;% \n        round(3) %&gt;% \n        as.character() %&gt;% \n        as_factor() %&gt;% \n        fct_reorder(as.numeric(model_id)),\n      logloss = logloss %&gt;% \n        round(4) %&gt;% \n        as.character() %&gt;% \n        as_factor() %&gt;% \n        fct_reorder(as.numeric(model_id))\n    ) %&gt;%\n    rename(\n      gain = cumulative_capture_rate,\n      lift = cumulative_lift\n    ) \n  \n  # 2A. Gain Plot\n  \n  p3 &lt;- gain_lift_tbl %&gt;%\n    ggplot(aes(cumulative_data_fraction, gain, \n               color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size,) +\n    geom_segment(x = 0, y = 0, xend = 1, yend = 1, \n                 color = \"red\", size = size, linetype = \"dotted\") +\n    theme_new +\n    expand_limits(x = c(0, 1), y = c(0, 1)) +\n    labs(title = \"Gain\",\n         x = \"Cumulative Data Fraction\", y = \"Gain\") +\n    theme(legend.position = \"none\")\n  \n  # 2B. Lift Plot\n  \n  p4 &lt;- gain_lift_tbl %&gt;%\n    ggplot(aes(cumulative_data_fraction, lift, \n               color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size) +\n    geom_segment(x = 0, y = 1, xend = 1, yend = 1, \n                 color = \"red\", size = size, linetype = \"dotted\") +\n    theme_new +\n    expand_limits(x = c(0, 1), y = c(0, 1)) +\n    labs(title = \"Lift\",\n         x = \"Cumulative Data Fraction\", y = \"Lift\") +\n    theme(legend.position = \"none\") \n  \n  \n  # Combine using cowplot\n  \n  # cowplot::get_legend extracts a legend from a ggplot object\n  p_legend &lt;- get_legend(p1)\n  # Remove legend from p1\n  p1 &lt;- p1 + theme(legend.position = \"none\")\n  \n  # cowplot::plt_grid() combines multiple ggplots into a single cowplot object\n  p &lt;- cowplot::plot_grid(p1, p2, p3, p4, ncol = 2)\n  \n  # cowplot::ggdraw() sets up a drawing layer\n  p_title &lt;- ggdraw() + \n    \n    # cowplot::draw_label() draws text on a ggdraw layer / ggplot object\n    draw_label(\"H2O Model Metrics\", size = 18, fontface = \"bold\", \n               color = \"#2C3E50\")\n  \n  p_subtitle &lt;- ggdraw() + \n    draw_label(glue(\"Ordered by {toupper(order_by)}\"), size = 10,  \n               color = \"#2C3E50\")\n  \n  # Combine everything\n  ret &lt;- plot_grid(p_title, p_subtitle, p, p_legend, \n                   \n                   # Adjust the relative spacing, so that the legends always fits\n                   ncol = 1, rel_heights = c(0.05, 0.05, 1, 0.05 * max_models))\n  \n  h2o.show_progress()\n  \n  return(ret)\n  \n}\n\nautoml_models_h2o@leaderboard %&gt;%\n  plot_h2o_performance(newdata = test_tbl, order_by = \"logloss\", \n                       size = 0.5, max_models = 4)\n\nAnd this the beatiful plot we get:\n\n\nH2O Model Metrics"
  },
  {
    "objectID": "content/01_journal/05_lime.html",
    "href": "content/01_journal/05_lime.html",
    "title": "Explaining Black-Box Models With LIME",
    "section": "",
    "text": "We use the first case from business case. The table is shown below.\n\nread.csv(\"05_LIME_files/explanation_single.csv\")\n\n\n\n  \n\n\n\nHere is the original plot:\n\nlibrary(lime)\nlibrary(tidyverse)\n\nexplanation_single &lt;- read.csv(\"05_LIME_files/explanation_single.csv\")\n\nexplanation_single %&gt;% \n  as.tibble()\n\n#&gt; Warning: `as.tibble()` was deprecated in tibble 2.0.0.\n#&gt; ℹ Please use `as_tibble()` instead.\n#&gt; ℹ The signature and semantics have changed, see `?as_tibble`.\n\n\n\n\n  \n\n\ncase_1 &lt;- explanation_single %&gt;%\n  filter(case == 1)\n\ncase_1 %&gt;%\n  plot_features()\n\n\n\n\n\n\n\nNow we recreate the plot. For details regarding my approach please look at my comments in the code.\n\n###Recreate the plot above\n###Part 1\n\n#Step 1 choose relevant columns\n#Create a new column which indicates the sign of the value feature weight to color it later respectively \nreplica1_tbl &lt;- case_1 %&gt;%\n  select(feature_weight, feature_desc, case, label_prob) %&gt;%\n  #To color the bars according to the sign of the value I deposited a value (Supports/Contradiction) which will tell the ggplot function which color the bar should have.\n  mutate(sign =  ifelse(feature_weight &gt;= 0, \"Supports\", \"Contradiction\")) %&gt;%\n  arrange(desc(abs(feature_weight))) \n\n\n#Plot\n#the reorder() function in aes() tells ggplot to order the vertical axis from high value to low value\n#the last argument \"fill\" indicates that the bars in the chart will be coloured according to the values in the sign column (Supports/Contradicition)\nggplot(data=replica1_tbl, aes(reorder(feature_desc, abs(feature_weight), sum), feature_weight, fill = sign)) +\n  #geom_col() indicates that we will plot a bar chart\n  geom_col() +\n  #I scanned the picture with a software and got the actual hex color values from the bars.\n  scale_fill_manual(values = c(\"Supports\" = \"#4983B2\", \"Contradiction\" = \"#B02427\")) +\n  #Here I needed to use the flip function\n  coord_flip() +\n  labs(y= \"Weight\", x = \"Feature\") +\n  theme(legend.position = \"bottom\") +\n  guides(fill=guide_legend(title=\"\")) +\n  #Okay here I have cheated :) In retrospect I could have taken the values from the tables, but somehow I didn't thought of it.\n  ggtitle(\" Case: 1\\n Label: No\\n Probability: 0.67\\n Explanation Fit: 0.35\")\n\n\n\n\n\n\n\n\nNo we take the data with multiple cases from the business case. The table is shown below.\n\nread.csv(\"05_LIME_files/explanation_multiple.csv\")\n\n\n\n  \n\n\n\nAgain here is the original plot for reference:\n\nexplanation_multiple &lt;- read.csv(\"05_LIME_files/explanation_multiple.csv\")\n\nexplanation_multiple %&gt;% \n  as.tibble()\n\n\n\n  \n\n\nplot_explanations(explanation_multiple)\n\n\n\n\n\n\n\nTo be honest with this task I was at a loss until I finally took a look at the library lime from Thomas Pedersens’ github page. Here is my replica of the plot:\n\n#This step was necessary to order th case numbers on the x axis otherwise they would have been jumbled.\n#I am aware that this approach is very problem specific. In the lime library is (of course) a general solution approach to this problem.\nexplanation_multiple$case &lt;- factor(explanation_multiple$case,levels = c(\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\"))\n\n\n#I copied a lot from the github code because I really didn't have a clue\n\nggplot(explanation_multiple, aes(case, feature_desc)) +\n  geom_tile(aes(fill = feature_weight)) +\n  scale_x_discrete('Case', expand = c(0, 0)) +\n  scale_y_discrete('Feature', expand = c(0, 0)) +\n  scale_fill_gradient2('Feature\\nweight', low = 'firebrick', mid = '#f7f7f7', high = 'steelblue') +\n  theme(panel.border = element_rect(fill = NA, colour = 'grey60', linewidth =  1),\n        panel.grid = element_blank(),\n        legend.position = 'right',\n        axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) +\n  facet_wrap(~label) +\n  #With the following code I tried to mimic the theme from the original \n  theme(legend.background = element_blank(), panel.background = element_blank(),axis.ticks = element_blank())\n\n\n\n\n\n\n#Close enough!\n\nSomehow I can’t find the issue now why the features here are sorted differently.\nIn the picture below, which is an export from the plot from my original code, you can see that the features are ordered right.\n\n\nplot_explanations() replica\n\nIn the class notes is my original code with which it worked like I intended it."
  },
  {
    "objectID": "content/01_journal/05_lime.html#part-1---recreate-plot_features",
    "href": "content/01_journal/05_lime.html#part-1---recreate-plot_features",
    "title": "Explaining Black-Box Models With LIME",
    "section": "",
    "text": "We use the first case from business case. The table is shown below.\n\nread.csv(\"05_LIME_files/explanation_single.csv\")\n\n\n\n  \n\n\n\nHere is the original plot:\n\nlibrary(lime)\nlibrary(tidyverse)\n\nexplanation_single &lt;- read.csv(\"05_LIME_files/explanation_single.csv\")\n\nexplanation_single %&gt;% \n  as.tibble()\n\n#&gt; Warning: `as.tibble()` was deprecated in tibble 2.0.0.\n#&gt; ℹ Please use `as_tibble()` instead.\n#&gt; ℹ The signature and semantics have changed, see `?as_tibble`.\n\n\n\n\n  \n\n\ncase_1 &lt;- explanation_single %&gt;%\n  filter(case == 1)\n\ncase_1 %&gt;%\n  plot_features()\n\n\n\n\n\n\n\nNow we recreate the plot. For details regarding my approach please look at my comments in the code.\n\n###Recreate the plot above\n###Part 1\n\n#Step 1 choose relevant columns\n#Create a new column which indicates the sign of the value feature weight to color it later respectively \nreplica1_tbl &lt;- case_1 %&gt;%\n  select(feature_weight, feature_desc, case, label_prob) %&gt;%\n  #To color the bars according to the sign of the value I deposited a value (Supports/Contradiction) which will tell the ggplot function which color the bar should have.\n  mutate(sign =  ifelse(feature_weight &gt;= 0, \"Supports\", \"Contradiction\")) %&gt;%\n  arrange(desc(abs(feature_weight))) \n\n\n#Plot\n#the reorder() function in aes() tells ggplot to order the vertical axis from high value to low value\n#the last argument \"fill\" indicates that the bars in the chart will be coloured according to the values in the sign column (Supports/Contradicition)\nggplot(data=replica1_tbl, aes(reorder(feature_desc, abs(feature_weight), sum), feature_weight, fill = sign)) +\n  #geom_col() indicates that we will plot a bar chart\n  geom_col() +\n  #I scanned the picture with a software and got the actual hex color values from the bars.\n  scale_fill_manual(values = c(\"Supports\" = \"#4983B2\", \"Contradiction\" = \"#B02427\")) +\n  #Here I needed to use the flip function\n  coord_flip() +\n  labs(y= \"Weight\", x = \"Feature\") +\n  theme(legend.position = \"bottom\") +\n  guides(fill=guide_legend(title=\"\")) +\n  #Okay here I have cheated :) In retrospect I could have taken the values from the tables, but somehow I didn't thought of it.\n  ggtitle(\" Case: 1\\n Label: No\\n Probability: 0.67\\n Explanation Fit: 0.35\")"
  },
  {
    "objectID": "content/01_journal/05_lime.html#part-2-recreate-plot_explanations",
    "href": "content/01_journal/05_lime.html#part-2-recreate-plot_explanations",
    "title": "Explaining Black-Box Models With LIME",
    "section": "",
    "text": "No we take the data with multiple cases from the business case. The table is shown below.\n\nread.csv(\"05_LIME_files/explanation_multiple.csv\")\n\n\n\n  \n\n\n\nAgain here is the original plot for reference:\n\nexplanation_multiple &lt;- read.csv(\"05_LIME_files/explanation_multiple.csv\")\n\nexplanation_multiple %&gt;% \n  as.tibble()\n\n\n\n  \n\n\nplot_explanations(explanation_multiple)\n\n\n\n\n\n\n\nTo be honest with this task I was at a loss until I finally took a look at the library lime from Thomas Pedersens’ github page. Here is my replica of the plot:\n\n#This step was necessary to order th case numbers on the x axis otherwise they would have been jumbled.\n#I am aware that this approach is very problem specific. In the lime library is (of course) a general solution approach to this problem.\nexplanation_multiple$case &lt;- factor(explanation_multiple$case,levels = c(\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\"))\n\n\n#I copied a lot from the github code because I really didn't have a clue\n\nggplot(explanation_multiple, aes(case, feature_desc)) +\n  geom_tile(aes(fill = feature_weight)) +\n  scale_x_discrete('Case', expand = c(0, 0)) +\n  scale_y_discrete('Feature', expand = c(0, 0)) +\n  scale_fill_gradient2('Feature\\nweight', low = 'firebrick', mid = '#f7f7f7', high = 'steelblue') +\n  theme(panel.border = element_rect(fill = NA, colour = 'grey60', linewidth =  1),\n        panel.grid = element_blank(),\n        legend.position = 'right',\n        axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) +\n  facet_wrap(~label) +\n  #With the following code I tried to mimic the theme from the original \n  theme(legend.background = element_blank(), panel.background = element_blank(),axis.ticks = element_blank())\n\n\n\n\n\n\n#Close enough!\n\nSomehow I can’t find the issue now why the features here are sorted differently.\nIn the picture below, which is an export from the plot from my original code, you can see that the features are ordered right.\n\n\nplot_explanations() replica\n\nIn the class notes is my original code with which it worked like I intended it."
  },
  {
    "objectID": "content/01_journal/01_ML_fundamentals.html",
    "href": "content/01_journal/01_ML_fundamentals.html",
    "title": "Machine Learning Fundamentals",
    "section": "",
    "text": "I save the comments because the code is quite well commented."
  },
  {
    "objectID": "content/01_journal/01_ML_fundamentals.html#which-stock-prices-behave-similary",
    "href": "content/01_journal/01_ML_fundamentals.html#which-stock-prices-behave-similary",
    "title": "Machine Learning Fundamentals",
    "section": "\n1.1 Which stock prices behave similary?",
    "text": "1.1 Which stock prices behave similary?\nStep 1 - Convert stock prices to a standardized format (daily returns)\nLoad librarys.\n\nlibrary(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.2     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.1     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidyquant)\n\n#&gt; Loading required package: PerformanceAnalytics\n#&gt; Loading required package: xts\n#&gt; Loading required package: zoo\n#&gt; \n#&gt; Attaching package: 'zoo'\n#&gt; \n#&gt; The following objects are masked from 'package:base':\n#&gt; \n#&gt;     as.Date, as.Date.numeric\n#&gt; \n#&gt; \n#&gt; ######################### Warning from 'xts' package ##########################\n#&gt; #                                                                             #\n#&gt; # The dplyr lag() function breaks how base R's lag() function is supposed to  #\n#&gt; # work, which breaks lag(my_xts). Calls to lag(my_xts) that you type or       #\n#&gt; # source() into this session won't work correctly.                            #\n#&gt; #                                                                             #\n#&gt; # Use stats::lag() to make sure you're not using dplyr::lag(), or you can add #\n#&gt; # conflictRules('dplyr', exclude = 'lag') to your .Rprofile to stop           #\n#&gt; # dplyr from breaking base R's lag() function.                                #\n#&gt; #                                                                             #\n#&gt; # Code in packages is not affected. It's protected by R's namespace mechanism #\n#&gt; # Set `options(xts.warn_dplyr_breaks_lag = FALSE)` to suppress this warning.  #\n#&gt; #                                                                             #\n#&gt; ###############################################################################\n#&gt; \n#&gt; Attaching package: 'xts'\n#&gt; \n#&gt; The following objects are masked from 'package:dplyr':\n#&gt; \n#&gt;     first, last\n#&gt; \n#&gt; \n#&gt; Attaching package: 'PerformanceAnalytics'\n#&gt; \n#&gt; The following object is masked from 'package:graphics':\n#&gt; \n#&gt;     legend\n#&gt; \n#&gt; Loading required package: quantmod\n#&gt; Loading required package: TTR\n#&gt; Registered S3 method overwritten by 'quantmod':\n#&gt;   method            from\n#&gt;   as.zoo.data.frame zoo\n\nlibrary(broom)\nlibrary(umap)\n\n\n# STOCK PRICES\nsp_500_prices_tbl &lt;- read_rds(\"01_ML_fundamentals_files/sp_500_prices_tbl.rds\")\nsp_500_prices_tbl\n\n\n\n  \n\n\n# SECTOR INFORMATION\nsp_500_index_tbl &lt;- read_rds(\"01_ML_fundamentals_files/sp_500_index_tbl.rds\")\nsp_500_index_tbl\n\n\n\n  \n\n\n### STEP 1 - Convert stock prices to a standardized format (daily returns) ###\n#Write solution in a new table called \"sp_500_daily_returns_tbl\", like given in task description\n\nsp_500_daily_returns_tbl &lt;- sp_500_prices_tbl %&gt;%\n  \n  #Select the symbol, date and adjusted columns\n  select(symbol, date, adjusted) %&gt;%\n  \n  #Filter to dates beginning in the year 2018 and beyond.\n  filter(date &gt; \"2018-01-01\") %&gt;%\n\n  #Compute a Lag of 1 day on the adjusted stock price. \n  #Be sure to group by symbol first, \n  #otherwise we will have lags computed using values from the previous stock in the data frame.\n  group_by(symbol) %&gt;%\n  mutate(adjusted_lag=lag(adjusted, n=1)) %&gt;%\n  \n  #Remove a NA values from the lagging operation\n  na.omit() %&gt;%\n  \n  #Compute the difference between adjusted and the lag\n  mutate(adjusted_diff = adjusted - adjusted_lag) %&gt;%\n  \n  #Compute the percentage difference by dividing the difference by that lag. \n  #Name this column pct_return.\n  mutate(pct_return = adjusted_diff/adjusted_lag) %&gt;%\n  \n  #Return only the symbol, date, and pct_return columns\n  ungroup() %&gt;%\n  select(symbol, date, pct_return)\n\nThe finished table looks like this:\n\nsp_500_daily_returns_tbl"
  },
  {
    "objectID": "content/01_journal/01_ML_fundamentals.html#step-2---convert-to-user-item-format",
    "href": "content/01_journal/01_ML_fundamentals.html#step-2---convert-to-user-item-format",
    "title": "Machine Learning Fundamentals",
    "section": "\n1.2 Step 2 - Convert to User-Item Format",
    "text": "1.2 Step 2 - Convert to User-Item Format\n\n### STEP 2 - Convert to User-Item Format ###\n\n  #Spread the date column to get the values as percentage returns. \n  #Save the result as stock_date_matrix_tbl\nstock_date_matrix_tbl &lt;- sp_500_daily_returns_tbl %&gt;%\n  spread(date, pct_return)\n#Fill NA values with zeros\nstock_date_matrix_tbl[is.na(stock_date_matrix_tbl)] &lt;- 0\n\n#Result\nstock_date_matrix_tbl"
  },
  {
    "objectID": "content/01_journal/01_ML_fundamentals.html#step-3---perform-k-means-clustering",
    "href": "content/01_journal/01_ML_fundamentals.html#step-3---perform-k-means-clustering",
    "title": "Machine Learning Fundamentals",
    "section": "\n1.3 Step 3 - Perform K-Means Clustering",
    "text": "1.3 Step 3 - Perform K-Means Clustering\n\n### STEP 3 - Perform K-Means Clustering ###\n  \n#Beginning with the stock_date_matrix_tbl, perform the following operations:\n#Drop the non-numeric column, symbol\n#Perform kmeans() with centers = 4 and nstart = 20\n#Save the result as kmeans_obj\n\nkmeans_obj &lt;- stock_date_matrix_tbl %&gt;%\n  #subset(select = -c(symbol)) %&gt;%\n  select(-symbol) %&gt;%\n  kmeans(centers = 4, nstart = 20)\n\n#Use glance() to get the tot.withinss\nglance(kmeans_obj)"
  },
  {
    "objectID": "content/01_journal/01_ML_fundamentals.html#step-4---find-the-optimal-value-of-k",
    "href": "content/01_journal/01_ML_fundamentals.html#step-4---find-the-optimal-value-of-k",
    "title": "Machine Learning Fundamentals",
    "section": "\n1.4 Step 4 - Find the optimal value of K",
    "text": "1.4 Step 4 - Find the optimal value of K\n\n### STEP 4 - Find the optimal value of K ###\nkmeans_mapper &lt;- function(center = 3) {\n  stock_date_matrix_tbl %&gt;%\n    select(-symbol) %&gt;%\n    kmeans(centers = center, nstart = 20)\n}\n\n#Apply the kmeans_mapper() and glance() functions iteratively using purrr.\n#Create a tibble containing column called centers that go from 1 to 30\n#Add a column named k_means with the kmeans_mapper() output. \n#Use mutate() to add the column and map() to map centers to the kmeans_mapper() function.\nlibrary(tibble)\nlibrary(purrr)\n\nk_means_mapped_tbl &lt;- tibble(centers = 1:30) %&gt;%\n  mutate(k_means = map(centers, kmeans_mapper)) %&gt;%\n  mutate(glance  = k_means %&gt;% map(glance))\n\n#Next, let’s visualize the “tot.withinss” from the glance output as a Scree Plot.\n\n#Begin with the k_means_mapped_tbl\n#Unnest the glance column\n\nk_means_mapped_tbl &lt;- k_means_mapped_tbl %&gt;%\n  unnest(glance)\n\n#Plot the centers column (x-axis) \n#versus the tot.withinss column (y-axis) using geom_point() and geom_line()\n#Add a title “Scree Plot” and feel free to style it with your favorite theme\n\nlibrary(ggplot2)\n\nggplot(k_means_mapped_tbl, aes(x = centers, y = tot.withinss)) +\n  geom_point() +\n  geom_line() +\n  labs(title = \"Scree Plot\") +\n  theme_minimal()"
  },
  {
    "objectID": "content/01_journal/01_ML_fundamentals.html#step-5---apply-umap",
    "href": "content/01_journal/01_ML_fundamentals.html#step-5---apply-umap",
    "title": "Machine Learning Fundamentals",
    "section": "\n1.5 Step 5 - Apply UMAP",
    "text": "1.5 Step 5 - Apply UMAP\n\n### STEP 5 - Apply UMAP ###\n\n#First, let’s apply the umap() function to the stock_date_matrix_tbl, \n#which contains our user-item matrix in tibble format.\n\n#Start with stock_date_matrix_tbl\n#De-select the symbol column --&gt; Already deselected in the last steps\n#Use the umap() function storing the output as umap_results\n\numap_results &lt;- stock_date_matrix_tbl %&gt;%\n  select(-symbol) %&gt;%\n  umap()\n\n#Next, we want to combine the layout from the umap_results with the symbol column from the stock_date_matrix_tbl.\n\n#Start with umap_results$layout\n#Convert from a matrix data type to a tibble with as_tibble()\n#Bind the columns of the umap tibble with the symbol column from the stock_date_matrix_tbl.\n#Save the results as umap_results_tbl.\n\numap_results_tbl &lt;- umap_results$layout %&gt;%\n  as_tibble() %&gt;% # argument is required to set names in the next step\n  #set_names(c(\"V1\", \"V2\")) %&gt;%\n  bind_cols(\n    stock_date_matrix_tbl %&gt;% select(symbol)\n  )\n\n#Finally, let’s make a quick visualization of the umap_results_tbl.\n\n#Pipe the umap_results_tbl into ggplot() mapping the columns to x-axis and y-axis\n#Add a geom_point() geometry with an alpha = 0.5\n#Apply theme_tq() and add a title “UMAP Projection”\n\n\numap_results_tbl %&gt;%\n  ggplot(aes(V1, V2)) +\n  geom_point(alpha = 0.5) + \n  labs(title = \"UMAP Projection\") +\n  theme_tq()"
  },
  {
    "objectID": "content/01_journal/01_ML_fundamentals.html#step-6---combine-k-means-and-umap",
    "href": "content/01_journal/01_ML_fundamentals.html#step-6---combine-k-means-and-umap",
    "title": "Machine Learning Fundamentals",
    "section": "\n1.6 Step 6 - Combine K-Means and UMAP",
    "text": "1.6 Step 6 - Combine K-Means and UMAP\n\n###STEP 6 - Combine K-Means and UMAP###\n\n#First, pull out the K-Means for 10 Centers. Use this since beyond this value the Scree Plot flattens.\n\nk_means_obj &lt;- k_means_mapped_tbl %&gt;%\n  pull(k_means) %&gt;%\n  pluck(10)\n\n\n#Next, we’ll combine the clusters from the k_means_obj with the umap_results_tbl.\n\n#Begin with the k_means_obj\n#Augment the k_means_obj with the stock_date_matrix_tbl to get the clusters added to the end of the tibble\n#Select just the symbol and .cluster columns\n#Left join the result with the umap_results_tbl by the symbol column\n#Left join the result with the result of sp_500_index_tbl %&gt;% select(symbol, company, sector) by the symbol column.\n#Store the output as umap_kmeans_results_tbl\n\numap_kmeans_results_tbl &lt;- k_means_obj %&gt;% \n  augment(stock_date_matrix_tbl)%&gt;%\n  select(symbol, .cluster) %&gt;%\n  left_join(umap_results_tbl, by = \"symbol\") %&gt;%\n  left_join(select(sp_500_index_tbl, symbol, company, sector), by = \"symbol\")\n\n\n#Plot the K-Means and UMAP results.\n\n#Begin with the umap_kmeans_results_tbl\n#Use ggplot() mapping V1, V2 and color = .cluster\n#Add the geom_point() geometry with alpha = 0.5\n#Apply colors as you desire (e.g. scale_color_manual(values = palette_light() %&gt;% rep(3)))\n\nggplot(umap_kmeans_results_tbl, aes(x = V1, y = V2, color = factor(.cluster))) +\n  geom_point(alpha = 0.5) +\n  scale_color_manual(values = rainbow(10) %&gt;% rep(3)) +\n  labs(title = \"Combined K-Means and UMAP Results\") +\n  theme_minimal()\n\n\n\n\n\n\n\nFinished."
  },
  {
    "objectID": "content/01_journal/02_supervised_ML.html",
    "href": "content/01_journal/02_supervised_ML.html",
    "title": "Supervised Machine Learning - Regression",
    "section": "",
    "text": "Challenge information taken from the course Website.\n\nBecause there were no further instructions we use the model from the business case\n\n#Step 1 - Build a Model\n\n\nlibrary(recipes)\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(rsample)\nlibrary(workflows)\nlibrary(parsnip)\n\n\nbike_features_tbl &lt;- readRDS(\"02_supervised_ML_files/bike_features_tbl.rds\") %&gt;%\n select(model, price, frame_material, weight) \n\n\nAs predictors I choose the weight. The outcome shall be the price of the bike. I know that weight alone is only a limited factor in predicting a prize, but as I understand it, the Challenge is all about the principle.\n\n# Step 2: Creating Features with recipes package\n\nbike_recipe &lt;- recipe(price ~ weight, data = bike_features_tbl) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) #%&gt;%\n  #step_rename(aluminium = frame_material_aluminium) %&gt;%\n  #step_rename(carbon = frame_material_carbon)\n\n#Apply recipe and bake\n\nbike_baked &lt;- prep(bike_recipe) %&gt;%\n  bake(new_data = bike_features_tbl) %&gt;%\n  mutate(model = bike_features_tbl$model)\n\n#Plot the data we have\n\nggplot(bike_baked, aes(x = price, y = weight)) +\n  geom_point() +\n  labs(title = \"Scatter Plot\", x = \"Price\", y = \"Weight\")\n\n\n\n\n\n\n# Step 3: Splitting into Training and Test Sets\nset.seed(1113)\nsplit_obj &lt;- initial_split(bike_baked, prop = 0.80)\n\ntrain_tbl &lt;- training(split_obj)\ntest_tbl &lt;- testing(split_obj)\n\nIn the scatter plot you can see that there is no linear relation. Therefore, I calculate not only a linear regression model but also a descision tree and a random forrest model (just because I am curious what the outcome is).\n\n\n#Bundle the model and recipe with the workflow package\n#linear regression model\nmodel_01_linear_lm_simple &lt;- linear_reg(mode = \"regression\")\n\n\n#Create a workflow object using the workflow() function. \n#Serves as a container for your model and recipe:\n#Model linear regression\n\nworkflow_obj &lt;- workflow(bike_recipe, model_01_linear_lm_simple) %&gt;%\nfit(data = train_tbl)\n\nmy_prediction &lt;- predict(workflow_obj, new_data = test_tbl)\n\ncomparison &lt;- my_prediction %&gt;%\n  mutate(weight = test_tbl$weight) %&gt;%\n  mutate(correct_price = test_tbl$price)\n\n\n#same for decision tree\n#decission tree model\nmodel_04_tree_decision_tree &lt;- decision_tree(mode = \"regression\",\n                                             \n                                             # Set the values accordingly to get started\n                                             cost_complexity = 0.001,\n                                             tree_depth      = 5,\n                                             min_n           = 7)\n\nworkflow_obj_tree &lt;- workflow(bike_recipe, model_04_tree_decision_tree) %&gt;%\n  fit(data = train_tbl)\n\nmy_prediction_tree &lt;- predict(workflow_obj_tree, new_data = test_tbl)\n\ncomparison_tree &lt;- my_prediction_tree%&gt;%\n  mutate(weight = test_tbl$weight) %&gt;%\n  mutate(correct_price = test_tbl$price)\n\n#random forest\nmodel_05_rand_forest &lt;- rand_forest(\n  mode = \"regression\", mtry = 8, trees = 5000, min_n = 10\n)\n\nworkflow_obj_forest &lt;- workflow(bike_recipe, model_05_rand_forest) %&gt;%\n  fit(data = train_tbl)\n\n#&gt; Warning: 8 columns were requested but there were 1 predictors in the data. 1\n#&gt; will be used.\n\nmy_prediction_forest &lt;- predict(workflow_obj_forest, new_data = test_tbl)\n\ncomparison_forest &lt;- my_prediction_forest%&gt;%\n  mutate(weight = test_tbl$weight) %&gt;%\n  mutate(correct_price = test_tbl$price)\n\n\nI evaluate all 3 models.\n\n#Evalute models\ncomparison %&gt;%\nyardstick::metrics(truth = correct_price, estimate = .pred)\n\n\n\n  \n\n\ncomparison_tree %&gt;%\n  yardstick::metrics(truth = correct_price, estimate = .pred)\n\n\n\n  \n\n\ncomparison_forest %&gt;%\n  yardstick::metrics(truth = correct_price, estimate = .pred)\n\n\n\n  \n\n\n\nIf we just look at metric RMSE, the random forest model performs the best (RMSE = 1274,37).\nAs I mentioned in the beginning you could see on the scatter plot, that there is no linear relation recognizable. Therefore it is no wonder, that the linear regression model performs worst (RMSE = 1617,32)."
  },
  {
    "objectID": "content/01_journal/02_supervised_ML.html#build-a-model",
    "href": "content/01_journal/02_supervised_ML.html#build-a-model",
    "title": "Supervised Machine Learning - Regression",
    "section": "",
    "text": "Because there were no further instructions we use the model from the business case\n\n#Step 1 - Build a Model\n\n\nlibrary(recipes)\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(rsample)\nlibrary(workflows)\nlibrary(parsnip)\n\n\nbike_features_tbl &lt;- readRDS(\"02_supervised_ML_files/bike_features_tbl.rds\") %&gt;%\n select(model, price, frame_material, weight)"
  },
  {
    "objectID": "content/01_journal/02_supervised_ML.html#create-features-with-the-recipes-package",
    "href": "content/01_journal/02_supervised_ML.html#create-features-with-the-recipes-package",
    "title": "Supervised Machine Learning - Regression",
    "section": "",
    "text": "As predictors I choose the weight. The outcome shall be the price of the bike. I know that weight alone is only a limited factor in predicting a prize, but as I understand it, the Challenge is all about the principle.\n\n# Step 2: Creating Features with recipes package\n\nbike_recipe &lt;- recipe(price ~ weight, data = bike_features_tbl) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) #%&gt;%\n  #step_rename(aluminium = frame_material_aluminium) %&gt;%\n  #step_rename(carbon = frame_material_carbon)\n\n#Apply recipe and bake\n\nbike_baked &lt;- prep(bike_recipe) %&gt;%\n  bake(new_data = bike_features_tbl) %&gt;%\n  mutate(model = bike_features_tbl$model)\n\n#Plot the data we have\n\nggplot(bike_baked, aes(x = price, y = weight)) +\n  geom_point() +\n  labs(title = \"Scatter Plot\", x = \"Price\", y = \"Weight\")\n\n\n\n\n\n\n# Step 3: Splitting into Training and Test Sets\nset.seed(1113)\nsplit_obj &lt;- initial_split(bike_baked, prop = 0.80)\n\ntrain_tbl &lt;- training(split_obj)\ntest_tbl &lt;- testing(split_obj)\n\nIn the scatter plot you can see that there is no linear relation. Therefore, I calculate not only a linear regression model but also a descision tree and a random forrest model (just because I am curious what the outcome is)."
  },
  {
    "objectID": "content/01_journal/02_supervised_ML.html#bundle-the-model-and-recipe-with-the-workflow-package",
    "href": "content/01_journal/02_supervised_ML.html#bundle-the-model-and-recipe-with-the-workflow-package",
    "title": "Supervised Machine Learning - Regression",
    "section": "",
    "text": "#Bundle the model and recipe with the workflow package\n#linear regression model\nmodel_01_linear_lm_simple &lt;- linear_reg(mode = \"regression\")\n\n\n#Create a workflow object using the workflow() function. \n#Serves as a container for your model and recipe:\n#Model linear regression\n\nworkflow_obj &lt;- workflow(bike_recipe, model_01_linear_lm_simple) %&gt;%\nfit(data = train_tbl)\n\nmy_prediction &lt;- predict(workflow_obj, new_data = test_tbl)\n\ncomparison &lt;- my_prediction %&gt;%\n  mutate(weight = test_tbl$weight) %&gt;%\n  mutate(correct_price = test_tbl$price)\n\n\n#same for decision tree\n#decission tree model\nmodel_04_tree_decision_tree &lt;- decision_tree(mode = \"regression\",\n                                             \n                                             # Set the values accordingly to get started\n                                             cost_complexity = 0.001,\n                                             tree_depth      = 5,\n                                             min_n           = 7)\n\nworkflow_obj_tree &lt;- workflow(bike_recipe, model_04_tree_decision_tree) %&gt;%\n  fit(data = train_tbl)\n\nmy_prediction_tree &lt;- predict(workflow_obj_tree, new_data = test_tbl)\n\ncomparison_tree &lt;- my_prediction_tree%&gt;%\n  mutate(weight = test_tbl$weight) %&gt;%\n  mutate(correct_price = test_tbl$price)\n\n#random forest\nmodel_05_rand_forest &lt;- rand_forest(\n  mode = \"regression\", mtry = 8, trees = 5000, min_n = 10\n)\n\nworkflow_obj_forest &lt;- workflow(bike_recipe, model_05_rand_forest) %&gt;%\n  fit(data = train_tbl)\n\n#&gt; Warning: 8 columns were requested but there were 1 predictors in the data. 1\n#&gt; will be used.\n\nmy_prediction_forest &lt;- predict(workflow_obj_forest, new_data = test_tbl)\n\ncomparison_forest &lt;- my_prediction_forest%&gt;%\n  mutate(weight = test_tbl$weight) %&gt;%\n  mutate(correct_price = test_tbl$price)"
  },
  {
    "objectID": "content/01_journal/02_supervised_ML.html#evaluate-your-model-with-the-yardstick-package",
    "href": "content/01_journal/02_supervised_ML.html#evaluate-your-model-with-the-yardstick-package",
    "title": "Supervised Machine Learning - Regression",
    "section": "",
    "text": "I evaluate all 3 models.\n\n#Evalute models\ncomparison %&gt;%\nyardstick::metrics(truth = correct_price, estimate = .pred)\n\n\n\n  \n\n\ncomparison_tree %&gt;%\n  yardstick::metrics(truth = correct_price, estimate = .pred)\n\n\n\n  \n\n\ncomparison_forest %&gt;%\n  yardstick::metrics(truth = correct_price, estimate = .pred)\n\n\n\n  \n\n\n\nIf we just look at metric RMSE, the random forest model performs the best (RMSE = 1274,37).\nAs I mentioned in the beginning you could see on the scatter plot, that there is no linear relation recognizable. Therefore it is no wonder, that the linear regression model performs worst (RMSE = 1617,32)."
  },
  {
    "objectID": "content/01_journal/03_automated_ML_h2o.html",
    "href": "content/01_journal/03_automated_ML_h2o.html",
    "title": "Automated Machine Learning with H2O",
    "section": "",
    "text": "In this challenge the task was to answer questions with the help of the plots that were generated. In order to Answer the questions we need the following 6 plots\n\nCompensation Features\nSurvey Results\nPerformance Data\nWork-Life Features\nTraining and Education\nTime-Based Features\n\n\n\n\nCompensation Features\n\nQuestions:\n\nWhat can you deduce about the interaction between Monthly Income and Attrition?\n\nAnswer: Those that are leaving have a lower Monthly Income\n\nWhat can you deduce about the interaction between Percent Salary Hike and Attrition?\n\nAnswer: Those that are leaving have lower Percent Salary Hike\n\nWhat can you deduce about the interaction between Stock Option Level and Attrition?\n\nAnswer: It’s difficult to deduce anything based on the visualization\n\n\n\nSurvey Results\n\nQuestions:\n\nWhat can you deduce about the interaction between Environment Satisfaction and Attrition?\n\nAnswer: A higher proportion of those leaving have a low environment satisfaction level\n\nWhat can you deduce about the interaction between Work Life Balance and Attrition?\n\nAnswer: Those that are staying have a higher density of 2’s and 3’s\n\n\n\nPerformance Data\n\nQuestions:\n\nWhat Can you deduce about the interaction between Job Involvement and Attrition?\n\nAnswer: Those that are leaving have a lower density of 3’s and 4’s\n\n\n\nWork-Life Features\n\nQuestions:\n\nWhat can you deduce about the interaction between Over Time and Attrition?\n\nAnswer: The proportion of those staying that are working Over Time are high compared to those that are not staying\n\n\n\nTraining and Education\n\nQuestions:\n\nWhat can you deduce about the interaction between Training Times Last Year and Attrition?\n\nAnswer: It’s difficult to deduce anything based on the visualization\n\n\n\nTime-Based Features\n\nQuestions:\n\nWhat can you deduce about the interaction between Years At Company and Attrition?\n\nAnswer: People that leave tend to have less working years at the company\n\nWhat can you deduce about the interaction between Years Since Last Promotion and Attrition?\n\nAnswer: Those that are leaving have fewer years since last promotion than those that are staying"
  },
  {
    "objectID": "content/01_journal/03_automated_ML_h2o.html#compensation-features",
    "href": "content/01_journal/03_automated_ML_h2o.html#compensation-features",
    "title": "Automated Machine Learning with H2O",
    "section": "",
    "text": "Compensation Features\n\nQuestions:\n\nWhat can you deduce about the interaction between Monthly Income and Attrition?\n\nAnswer: Those that are leaving have a lower Monthly Income\n\nWhat can you deduce about the interaction between Percent Salary Hike and Attrition?\n\nAnswer: Those that are leaving have lower Percent Salary Hike\n\nWhat can you deduce about the interaction between Stock Option Level and Attrition?\n\nAnswer: It’s difficult to deduce anything based on the visualization"
  },
  {
    "objectID": "content/01_journal/03_automated_ML_h2o.html#survey-results",
    "href": "content/01_journal/03_automated_ML_h2o.html#survey-results",
    "title": "Automated Machine Learning with H2O",
    "section": "",
    "text": "Survey Results\n\nQuestions:\n\nWhat can you deduce about the interaction between Environment Satisfaction and Attrition?\n\nAnswer: A higher proportion of those leaving have a low environment satisfaction level\n\nWhat can you deduce about the interaction between Work Life Balance and Attrition?\n\nAnswer: Those that are staying have a higher density of 2’s and 3’s"
  },
  {
    "objectID": "content/01_journal/03_automated_ML_h2o.html#performance-data",
    "href": "content/01_journal/03_automated_ML_h2o.html#performance-data",
    "title": "Automated Machine Learning with H2O",
    "section": "",
    "text": "Performance Data\n\nQuestions:\n\nWhat Can you deduce about the interaction between Job Involvement and Attrition?\n\nAnswer: Those that are leaving have a lower density of 3’s and 4’s"
  },
  {
    "objectID": "content/01_journal/03_automated_ML_h2o.html#work-life-features",
    "href": "content/01_journal/03_automated_ML_h2o.html#work-life-features",
    "title": "Automated Machine Learning with H2O",
    "section": "",
    "text": "Work-Life Features\n\nQuestions:\n\nWhat can you deduce about the interaction between Over Time and Attrition?\n\nAnswer: The proportion of those staying that are working Over Time are high compared to those that are not staying"
  },
  {
    "objectID": "content/01_journal/03_automated_ML_h2o.html#training-and-education",
    "href": "content/01_journal/03_automated_ML_h2o.html#training-and-education",
    "title": "Automated Machine Learning with H2O",
    "section": "",
    "text": "Training and Education\n\nQuestions:\n\nWhat can you deduce about the interaction between Training Times Last Year and Attrition?\n\nAnswer: It’s difficult to deduce anything based on the visualization"
  },
  {
    "objectID": "content/01_journal/03_automated_ML_h2o.html#time-based-features",
    "href": "content/01_journal/03_automated_ML_h2o.html#time-based-features",
    "title": "Automated Machine Learning with H2O",
    "section": "",
    "text": "Time-Based Features\n\nQuestions:\n\nWhat can you deduce about the interaction between Years At Company and Attrition?\n\nAnswer: People that leave tend to have less working years at the company\n\nWhat can you deduce about the interaction between Years Since Last Promotion and Attrition?\n\nAnswer: Those that are leaving have fewer years since last promotion than those that are staying"
  },
  {
    "objectID": "content/02_notes/05_class_notes.html",
    "href": "content/02_notes/05_class_notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "My original code for the LIME challenge:\n\n# LIME FEATURE EXPLANATION ----\n\n# 1. Setup ----\n\n# Load Libraries \n\nlibrary(h2o)\nlibrary(recipes)\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(tidyquant)\nlibrary(lime)\nlibrary(rsample)\n\n\n# Load Data\nemployee_attrition_tbl &lt;- read_csv(\"datasets-1067-1925-WA_Fn-UseC_-HR-Employee-Attrition.csv\")\ndefinitions_raw_tbl    &lt;- read_excel(\"data_definitions.xlsx\", sheet = 1, col_names = FALSE)\n\n#Source Code was not given, lets hope I can take the table from the H2O Business Case\n\nemployee_attrition_readable_tbl &lt;- readRDS(\"employee_attrition_tbl.rds\")\n\n# Split into test and train\nset.seed(seed = 1113)\nsplit_obj &lt;- rsample::initial_split(employee_attrition_readable_tbl, prop = 0.85)\n\n# Assign training and test data\ntrain_readable_tbl &lt;- training(split_obj)\ntest_readable_tbl  &lt;- testing(split_obj)\n\n# ML Preprocessing Recipe \nrecipe_obj &lt;- recipe(Attrition ~ ., data = train_readable_tbl) %&gt;%\n  step_zv(all_predictors()) %&gt;%\n  step_mutate_at(c(\"JobLevel\", \"StockOptionLevel\"), fn = as.factor) %&gt;% \n  prep()\n\nrecipe_obj\n\ntrain_tbl &lt;- bake(recipe_obj, new_data = train_readable_tbl)\ntest_tbl  &lt;- bake(recipe_obj, new_data = test_readable_tbl)\n\n# 2. Models ----\n\nh2o.init()\n\n#we calculate a new model \nsplit_h2o &lt;- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.85), seed = 1234)\ntrain_h2o &lt;- split_h2o[[1]]\nvalid_h2o &lt;- split_h2o[[2]]\ntest_h2o  &lt;- as.h2o(test_tbl)\n\n# Set the target and predictors\ny &lt;- \"Attrition\"\nx &lt;- setdiff(names(train_h2o), y)\n\n#Compute the models\n\nautoml_models_h2o &lt;- h2o.automl(\n  x = x,\n  y = y,\n  training_frame    = train_h2o,\n  validation_frame  = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs  = 30,\n  nfolds            = 5 \n)\n\nautoml_models_h2o@leaderboard\n\n#Take the best model from the calculation\n\nautoml_leader &lt;-h2o.getModel(\"StackedEnsemble_AllModels_2_AutoML_10_20230611_191016\")\nautoml_leader\n\n\n# 3. LIME ----\n\n# 3.1 Making Predictions ----\n\npredictions_tbl &lt;- automl_leader %&gt;% \n  h2o.predict(newdata = as.h2o(test_tbl)) %&gt;%\n  as.tibble() %&gt;%\n  bind_cols(\n    test_tbl %&gt;%\n      select(Attrition, EmployeeNumber)\n  )\n\npredictions_tbl\n\n#Let’s investigate the 1st employee, that did indeed leave the company:\ntest_tbl %&gt;%\n  slice(1) %&gt;%\n  glimpse()\n\n\n\n# 3.2 Single Explanation ----\n\nexplainer &lt;- train_tbl %&gt;%\n  select(-Attrition) %&gt;%\n  lime(\n    model           = automl_leader,\n    bin_continuous  = TRUE,\n    n_bins          = 4,\n    quantile_bins   = TRUE\n  )\n\nexplainer\n\n\nexplanation_single &lt;- test_tbl %&gt;%\n  slice(1) %&gt;%\n  select(-Attrition) %&gt;%\n  lime::explain(\n    \n    # Pass our explainer object\n    explainer = explainer,\n    # Because it is a binary classification model: 1\n    n_labels   = 1,\n    # number of features to be returned\n    n_features = 8,\n    # number of localized linear models\n    n_permutations = 5000,\n    # Let's start with 1\n    kernel_width   = 1\n  )\n\nexplanation\n\nexplanation %&gt;%\n  as.tibble() %&gt;%\n  select(feature:prediction) \n\nplot_features(explanation = explanation_single, ncol = 1)\n\n\n\n# 3.3 Multiple Explanations ----\n\nexplanation_multiple &lt;- test_tbl %&gt;%\n  slice(1:20) %&gt;%\n  select(-Attrition) %&gt;%\n  lime::explain(\n    explainer = explainer,\n    n_labels   = 1,\n    n_features = 8,\n    n_permutations = 5000,\n    kernel_width   = 0.5\n  )\n\nexplanation_multiple %&gt;%\n  as.tibble()\n\n#Messy plot\nplot_features(explanation, ncol = 4)\n\n#Still hard to read\nplot_explanations(explanation_multiple)\n\n\n\n######CHALLENGE\nexplanation_single %&gt;% \n  as.tibble()\n\ncase_1 &lt;- explanation_single %&gt;%\n  filter(case == 1)\n\ncase_1 %&gt;%\n  plot_features()\n\n###Recreate the plot above\n###Part 1\n\n#Step 1 choose relevant columns\n#Create a new column which indicates the sign of the value feature weight to color it later respectivly \nreplica1_tbl &lt;- case_1 %&gt;%\n  select(feature_weight, feature_desc, case, label_prob) %&gt;%\n  mutate(sign =  ifelse(feature_weight &gt;= 0, \"Supports\", \"Contradiction\")) %&gt;%\n  arrange(desc(abs(feature_weight))) \n\n\n#plot\nggplot(data=replica1_tbl, aes(reorder(feature_desc, abs(feature_weight), sum), feature_weight, fill = sign)) +\n  geom_col() +\n  scale_fill_manual(values = c(\"Supports\" = \"#4983B2\", \"Contradiction\" = \"#B02427\")) +\n  coord_flip() +\n  labs(y= \"Weight\", x = \"Feature\") +\n  theme(legend.position = \"bottom\") +\n  guides(fill=guide_legend(title=\"\")) +\n  ggtitle(\" Case: 1\\n Label: No\\n Probability: 0.67\\n Explanation Fit: 0.35\")\n\n###Part 2 \n#Recreate the plot_explanations()\n\n\n\nplot_explanations(explanation_multiple)\n\n#explanation_multiple$feature_desc &lt;- factor(\n#  explanation_multiple$feature_desc,\n#  levels = rev(unique(explanation_multiple$feature_desc[order(explanation_multiple$feature, explanation_multiple$feature_value)]))\n#)\n\n\n#Essentially I think I do the same as the code above but in a more specific way adapted to the data I work with\nexplanation_multiple$case &lt;- factor(explanation_multiple$case,levels = c(\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\"))\n\n\n#I copied a lot from the github code because I really didnt have a clue\n\nggplot(explanation_multiple, aes(case, feature_desc)) +\n  geom_tile(aes(fill = feature_weight)) +\n  scale_x_discrete('Case', expand = c(0, 0)) +\n  scale_y_discrete('Feature', expand = c(0, 0)) +\n  scale_fill_gradient2('Feature\\nweight', low = 'firebrick', mid = '#f7f7f7', high = 'steelblue') +\n  theme(panel.border = element_rect(fill = NA, colour = 'grey60', linewidth =  1),\n        panel.grid = element_blank(),\n        legend.position = 'right',\n        axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) +\n  facet_wrap(~label) +\n  theme(legend.background = element_blank(), panel.background = element_blank(),axis.ticks = element_blank())\n\n\n#Close enough!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is my lab journal for the course “Business Decisions with Machine Learning”."
  },
  {
    "objectID": "index.html#overall-conclusion",
    "href": "index.html#overall-conclusion",
    "title": "My Lab Journal",
    "section": "Overall Conclusion",
    "text": "Overall Conclusion\nThe teaching content was really nicely prepared. I especially liked the videos that were used as explanations. This helped to understand the topic even better. I have already participated in the course “Business Data Science Basics” a year ago. The scope was similar in this course. There was a lot to do and it was definitely a challenge. But I learned an incredible amount of useful stuff.\nIt was very interesting. Thank you :-)"
  }
]